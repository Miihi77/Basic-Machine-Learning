{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOg9Amg0NRZBbVLAdMelqtN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Miihi77/Basic-Machine-Learning/blob/main/Image_Scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Used in process of copying and removal of files and directories.\n",
        "import shutil"
      ],
      "metadata": {
        "id": "BL-rRp1u5uPS"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Installation for Image Crawler\n",
        "!pip install icrawler"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzK9674F4Tu6",
        "outputId": "2d3add89-06ce-4f47-e8af-98fd0c39d29b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting icrawler\n",
            "  Downloading icrawler-0.6.10-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from icrawler) (4.13.4)\n",
            "Collecting bs4 (from icrawler)\n",
            "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from icrawler) (5.4.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from icrawler) (11.2.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from icrawler) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from icrawler) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from icrawler) (1.17.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->icrawler) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->icrawler) (4.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->icrawler) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->icrawler) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->icrawler) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->icrawler) (2025.6.15)\n",
            "Downloading icrawler-0.6.10-py3-none-any.whl (36 kB)\n",
            "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
            "Installing collected packages: bs4, icrawler\n",
            "Successfully installed bs4-0.0.2 icrawler-0.6.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code 1:\n",
        "DateTime which is used for date related functions. We can use this to help label our images, but it is not necessary for now.\n",
        "\n",
        "# Code 2:\n",
        "iCrawler library which is a fairly popular tool for image scraping using popular search engines.\n",
        "\n",
        "# Code 3:\n",
        "Google Colab, to allow us to store images in this instance of a colaboratory file, so that we can download the images later.\n",
        "\n",
        "# Code 4:\n",
        "The fourth library is Pathlib, for defining the folder paths we will be storing our images in.\n",
        "\n",
        "# Code 5:\n",
        "OS, which is used for creating and managing folders in Google Drive and Google Colab."
      ],
      "metadata": {
        "id": "K8YWFO-t19Gr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2d_QuwfH0BJh"
      },
      "outputs": [],
      "source": [
        "from datetime import date\n",
        "from icrawler.builtin import BaiduImageCrawler, BingImageCrawler, GoogleImageCrawler\n",
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "import os\n",
        "import shutil\n",
        "import os.path\n",
        "from os import path"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Folder Creation\n",
        "# You can also edit what name you wanted in os.mkdir('/content/images/name_of_images')\n",
        "\n",
        "if path.exists('/content/drive') == False:\n",
        "  os.mkdir('/content/images')\n",
        "  os.mkdir('/content/images/mulberries_images')\n",
        "  os.mkdir('/content/images/raspberry_images')\n",
        "  os.mkdir('/content/images/redCurrant_images')\n",
        "  os.mkdir('/content/images/whiteCurrant_images')\n",
        "root = Path.cwd()/\"images\""
      ],
      "metadata": {
        "id": "Z-FeOz170hSk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For removing file and folders\n",
        "\n",
        "folder_to_remove = '/content/images'\n",
        "\n",
        "if os.path.exists(folder_to_remove):\n",
        "\n",
        "    shutil.rmtree(folder_to_remove)\n",
        "    print(f\"Folder '{folder_to_remove}' and its contents have been successfully removed.\")\n",
        "\n",
        "else:\n",
        "    print(f\"Folder '{folder_to_remove}' does not exist.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIPRtVSI538u",
        "outputId": "2101cc76-ade6-4e5f-fcaa-ca66b39d3e40"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder '/content/images' and its contents have been successfully removed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Search Image using Image Crawler\n",
        "\n",
        "This code uses a simple google image crawler to scrape images on the internet.\n",
        "\n",
        "You can just edit the following like keyword, filter, max number, and file idx but dont forget to edit the root_dir for the images to be sent on a folder you created.\n",
        "\n",
        "Error may occur but its pretty much normal during scraping session."
      ],
      "metadata": {
        "id": "LFI90RRi1eN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "google_crawler = GoogleImageCrawler(downloader_threads=4, storage={'root_dir': '/content/images/mulberries_images'})\n",
        "google_crawler.crawl(keyword='images of mulberries', filters=None, max_num=100, file_idx_offset='auto')"
      ],
      "metadata": {
        "id": "foOijJAB06mY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "google_crawler = GoogleImageCrawler(downloader_threads=4, storage={'root_dir': '/content/images/raspberry_images'})\n",
        "google_crawler.crawl(keyword='images of rasberries', filters=None, max_num=100, file_idx_offset='auto')"
      ],
      "metadata": {
        "id": "PSnt44491Hqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "google_crawler = GoogleImageCrawler(downloader_threads=4, storage={'root_dir': '/content/images/redCurrant_images'})\n",
        "google_crawler.crawl(keyword='images of red Currant berries', filters=None, max_num=100, file_idx_offset='auto')"
      ],
      "metadata": {
        "id": "6Rz6RcAz1J-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "google_crawler = GoogleImageCrawler(downloader_threads=4, storage={'root_dir': '/content/images/whiteCurrant_images'})\n",
        "google_crawler.crawl(keyword='images of white Currant berries', filters=None, max_num=100, file_idx_offset='auto')"
      ],
      "metadata": {
        "id": "F4OSOOQk1L6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# File setup\n",
        "\n",
        "This code zips the image that has been scraped earlier then its ready to be downloaded after zipping."
      ],
      "metadata": {
        "id": "_V85NPdu2cZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the name of the zip file that will be downloaded. We will be storing all our images here.\n",
        "ZIP_NAME = \"image_set.zip\"\n",
        "\n",
        "# These commands tell colab to place all the content in our \"Files\" on the left hand side into the zip file.\n",
        "# It then stores the zip file in the \"Files\" for later use.\n",
        "!rm -f {ZIP_NAME}\n",
        "!zip -q -r {ZIP_NAME} {root}"
      ],
      "metadata": {
        "id": "HXeXt2KG1XOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This code takes the zip file and downloads it.\n",
        "from google.colab import files\n",
        "files.download(ZIP_NAME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "fC9hiCKj2WzW",
        "outputId": "0bb89ae0-26a2-4e5d-9d74-1ffd808c2214"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a9dbc9e5-62ea-4046-9488-9d0b68068567\", \"image_set.zip\", 227040127)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}