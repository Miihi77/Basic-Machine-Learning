{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNnXbj0uzKQ9ltBbdEUZYux",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Miihi77/Machine/blob/main/Image_Scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code 1:\n",
        "DateTime which is used for date related functions. We can use this to help label our images, but it is not necessary for now.\n",
        "\n",
        "# Code 2:\n",
        "iCrawler library which is a fairly popular tool for image scraping using popular search engines.\n",
        "\n",
        "# Code 3:\n",
        "Google Colab, to allow us to store images in this instance of a colaboratory file, so that we can download the images later.\n",
        "\n",
        "# Code 4:\n",
        "The fourth library is Pathlib, for defining the folder paths we will be storing our images in.\n",
        "\n",
        "# Code 5:\n",
        "OS, which is used for creating and managing folders in Google Drive and Google Colab."
      ],
      "metadata": {
        "id": "K8YWFO-t19Gr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2d_QuwfH0BJh"
      },
      "outputs": [],
      "source": [
        "from datetime import date\n",
        "from icrawler.builtin import BaiduImageCrawler, BingImageCrawler, GoogleImageCrawler\n",
        "from google.colab import Path\n",
        "import os.path\n",
        "from os import path"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Folder Creation\n",
        "if path.exists('/content/drive') == False:\n",
        "  os.mkdir('/content/images')\n",
        "  os.mkdir('/content/images/leopard_images')\n",
        "  os.mkdir('/content/images/lynx_images')\n",
        "  os.mkdir('/content/images/cheetah_images')\n",
        "  os.mkdir('/content/images/puma_images')\n",
        "root = Path.cwd()/\"images\""
      ],
      "metadata": {
        "id": "Z-FeOz170hSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Search Image using Image Crawler\n",
        "\n",
        "This code uses a simple google image crawler to scrape images on the internet"
      ],
      "metadata": {
        "id": "LFI90RRi1eN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "google_crawler = GoogleImageCrawler(downloader_threads=4, storage={'root_dir': '/content/images/leopard_images'})\n",
        "google_crawler.crawl(keyword='adult leopard', filters=None, max_num=100, file_idx_offset='auto')"
      ],
      "metadata": {
        "id": "foOijJAB06mY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "google_crawler = GoogleImageCrawler(downloader_threads=4, storage={'root_dir': '/content/images/lynx_images'})\n",
        "google_crawler.crawl(keyword='adult lynx', filters=None, max_num=100, file_idx_offset='auto')"
      ],
      "metadata": {
        "id": "PSnt44491Hqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "google_crawler = GoogleImageCrawler(downloader_threads=4, storage={'root_dir': '/content/images/cheetah_images'})\n",
        "google_crawler.crawl(keyword='adult cheetah', filters=None, max_num=100, file_idx_offset='auto')"
      ],
      "metadata": {
        "id": "6Rz6RcAz1J-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "google_crawler = GoogleImageCrawler(downloader_threads=4, storage={'root_dir': '/content/images/puma_images'})\n",
        "google_crawler.crawl(keyword='adult lpuma', filters=None, max_num=100, file_idx_offset='auto')"
      ],
      "metadata": {
        "id": "F4OSOOQk1L6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# File setup\n",
        "This code zips the image that has been scraped earlier then its ready to be downloaded after zipping."
      ],
      "metadata": {
        "id": "_V85NPdu2cZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the name of the zip file that will be downloaded. We will be storing all our images here.\n",
        "ZIP_NAME = \"image_set.zip\"\n",
        "\n",
        "# These commands tell colab to place all the content in our \"Files\" on the left hand side into the zip file.\n",
        "# It then stores the zip file in the \"Files\" for later use.\n",
        "!rm -f {ZIP_NAME}\n",
        "!zip -q -r {ZIP_NAME} {root}"
      ],
      "metadata": {
        "id": "HXeXt2KG1XOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This code takes the zip file and downloads it.\n",
        "from google.colab import files\n",
        "files.download(ZIP_NAME)"
      ],
      "metadata": {
        "id": "fC9hiCKj2WzW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}